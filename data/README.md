# Data

This directory contains the input data and the structure for processed artifacts for the LocalRAG pipeline evaluation.

## Directory Structure:

### Processed Data (Generated by `scripts/create_index.py` - not included in the repository)

- **`processed_corpora/`**: Contains standardized corpus files in JSONL format for each dataset.
  - `clapnq_corpus.jsonl`: ClapNQ corpus passages
  - `triviaqa_corpus.jsonl`: TriviaQA corpus passages 
  - `hotpotqa_corpus.jsonl`: HotpotQA corpus passages
  - Each entry has a consistent format: `{"passage_id": "...", "text": "...", "title": "..."}`

- **`processed_questions/`**: Contains standardized question files in JSONL format for each dataset.
  - `clapnq_questions.jsonl`: ClapNQ questions
  - `triviaqa_questions.jsonl`: TriviaQA questions
  - `hotpotqa_questions.jsonl`: HotpotQA questions
  - Each entry has a consistent format: `{"question_id": "...", "question_text": "...", "gold_answer": "...", "is_answerable": true/false, "gold_passage_ids": ["id1", "id2", ...]}`

- **`subsets/`**: Contains JSON files with question IDs for reproducible subset evaluation.
  - `clapnq_N_qids.json`: ClapNQ subset with N questions
  - `triviaqa_N_qids.json`: TriviaQA subset with N questions
  - `hotpotqa_N_qids.json`: HotpotQA subset with N questions
  - These files ensure that different models evaluated on the same dataset with the same limit value use identical question subsets.

### Original ClapNQ Data (Included in the repository)

- **`retrieval/dev/`**: Contains the retrieval ground truth (qrels) for the ClapNQ development set in TSV format.
  - `question_dev_answerable.tsv`: Ground truth for answerable questions.
  - `question_dev_unanswerable.tsv`: Ground truth for unanswerable questions (by definition empty).

## Data Sources

- **ClapNQ**: Processed from `PrimeQA/clapnq` and `PrimeQA/clapnq_passages` on Hugging Face, combined with the original TSV files for qrels.
- **TriviaQA**: Processed entirely from `trivia_qa` (config: "rc") on Hugging Face.
- **HotpotQA**: Processed entirely from `hotpot_qa` (config: "distractor") on Hugging Face.

**Note:** The raw datasets are downloaded dynamically from the Hugging Face Hub by the `scripts/create_index.py` script through the `datasets` library, not stored directly in this directory. The processed files are created to provide a standardized format across all datasets.